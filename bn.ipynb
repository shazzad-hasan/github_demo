{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bn.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOqUni1Y5VN8ZYXYgj4CvFW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shazzad-hasan/github_demo/blob/main/bn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKKiqPew0lvP",
        "outputId": "0e427b38-6112-4f7a-e2a1-1829126bcfa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/Questions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhQS08wE0tI1",
        "outputId": "c515a949-5aa0-4cbf-f8c9-c4b8ab867571"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Questions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEblaE_h09Ba",
        "outputId": "f6c5cb54-1a5e-4f96-a5ac-e71f149ae5b4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corpus.train.bn  corpus.train.en\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bnlp_toolkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCBM88cd62yQ",
        "outputId": "b933fcbc-344a-400c-aa3e-6030384da230"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bnlp_toolkit\n",
            "  Downloading bnlp_toolkit-3.1.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (1.4.1)\n",
            "Collecting gensim==4.0.1\n",
            "  Downloading gensim-4.0.1-cp37-cp37m-manylinux1_x86_64.whl (23.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.9 MB 67.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (1.21.6)\n",
            "Requirement already satisfied: wasabi in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (0.9.1)\n",
            "Collecting sklearn-crfsuite\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.0.1->bnlp_toolkit) (6.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->bnlp_toolkit) (1.15.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (4.64.0)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "  Downloading python_crfsuite-0.9.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 57.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (0.8.9)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite, sentencepiece, gensim, bnlp-toolkit\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed bnlp-toolkit-3.1.2 gensim-4.0.1 python-crfsuite-0.9.8 sentencepiece-0.1.96 sklearn-crfsuite-0.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIcAYBYtJotq",
        "outputId": "995f01c1-6615-4c6a-fbcc-083ec71fd516"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bltk\n",
            "  Downloading bltk-1.2.tar.gz (17.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.4 MB 7.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn>=0.0 in /usr/local/lib/python3.7/dist-packages (from bltk) (0.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from bltk) (1.15.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from bltk) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from bltk) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.7/dist-packages (from bltk) (1.21.6)\n",
            "Collecting nltk>=3.4.5\n",
            "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 39.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.7/dist-packages (from bltk) (1.1.0)\n",
            "Requirement already satisfied: certifi>=2019.11.28 in /usr/local/lib/python3.7/dist-packages (from bltk) (2021.10.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk>=3.4.5->bltk) (4.64.0)\n",
            "Collecting regex>=2021.8.3\n",
            "  Downloading regex-2022.4.24-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
            "\u001b[K     |████████████████████████████████| 749 kB 63.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.4.5->bltk) (7.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->bltk) (3.1.0)\n",
            "Building wheels for collected packages: bltk\n",
            "  Building wheel for bltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bltk: filename=bltk-1.2-py3-none-any.whl size=17432539 sha256=ce19d3ef085ded6bc9c93b11419b62bdb52d9d7b0bacc53b67849f7d0a3e5dbf\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/4f/91/e074e661b4dcbc24a83e050d1c75cecfa186ffe9d58b641c51\n",
            "Successfully built bltk\n",
            "Installing collected packages: regex, nltk, bltk\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed bltk-1.2 nltk-3.7 regex-2022.4.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bangla-stemmer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8UwaRyQC_Wr",
        "outputId": "8287c303-dfd3-491e-a23f-fabb9938917c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bangla-stemmer\n",
            "  Downloading bangla_stemmer-1.0-py3-none-any.whl (9.1 kB)\n",
            "Installing collected packages: bangla-stemmer\n",
            "Successfully installed bangla-stemmer-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/banglakit/lemmatizer.git#egg=banglakit-lemmatizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDhgbmDTEHee",
        "outputId": "eaf722b2-57b0-4770-d4a0-4864ba4e334a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting banglakit-lemmatizer\n",
            "  Cloning https://github.com/banglakit/lemmatizer.git to /tmp/pip-install-d_sb2bzz/banglakit-lemmatizer_973d321f29b04f64ae89b2868b6cccf3\n",
            "  Running command git clone -q https://github.com/banglakit/lemmatizer.git /tmp/pip-install-d_sb2bzz/banglakit-lemmatizer_973d321f29b04f64ae89b2868b6cccf3\n",
            "Building wheels for collected packages: banglakit-lemmatizer\n",
            "  Building wheel for banglakit-lemmatizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for banglakit-lemmatizer: filename=banglakit_lemmatizer-0.0.1-py3-none-any.whl size=117718 sha256=363d0e3a377616c2578c2ac31cce6923eff7ca37fbec24041e3caae5ad6ace39\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ovd50bba/wheels/3f/67/0f/a2d1a5758cee58b4521b0f8a150c9f5dca02d0c2c229d58cd7\n",
            "Successfully built banglakit-lemmatizer\n",
            "Installing collected packages: banglakit-lemmatizer\n",
            "Successfully installed banglakit-lemmatizer-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import bnlp\n",
        "from bnlp import NLTKTokenizer\n",
        "\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjX0sbyv09IJ",
        "outputId": "b2a9aa94-56c8-46aa-88b8-ae42bc14983e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "punkt not found. downloading...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "/usr/local/lib/python3.7/dist-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "n_Jxn5wPnwqf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and read the dataset"
      ],
      "metadata": {
        "id": "_DFPbOziLJMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read the dataset from the directory\n",
        "file = open('corpus.train.bn', encoding = 'utf8').read()"
      ],
      "metadata": {
        "id": "ltfsa3iq09FH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "id": "nKYdzbJwnxLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess dataset \n",
        "\n",
        "file_nl_removed = \"\"\n",
        "\n",
        "for line in file:\n",
        "  # remove new lines\n",
        "  line_nl_removed = line.replace(\"\\n\", \" \")     \n",
        "  file_nl_removed += line_nl_removed\n",
        "\n",
        "# remove all special characters\n",
        "file_p = \"\".join([char for char in file_nl_removed])\n",
        "file_p = \"\".join(i for i in file_p if i in [\"।\"] or 2432 <= ord(i) <= 2559 or ord(i)== 32)"
      ],
      "metadata": {
        "id": "qSwdlkT_Fuwx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_p[:1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "R8_RhCWKL0X-",
        "outputId": "e5867b1a-dbc4-4cf6-8b4e-6aa1a17b2acf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'আবার সবাইকে যার যার ইচ্ছামতো চলতে দিলে সমতা রক্ষা করা অসম্ভব হয়ে যায়। তুরুপ পদদলিত করা সেগুলো হৃদয়কে উষ্ণ করে এবং রোজকার বোঝাগুলোকে হালকা করে। আমি ভালোবাসি তোমাকে । পোর্ট কোম্পানি লিমিটেড  কেপিসিএল তোলপাড় এছাড়াও ক্লেমঁসো উইলসনের ১৪ দফার ব্যাপারে সংশয়ী এবং হতাশ ছিলেন। তিনি অভিযোগ করে বলেন মিস্টার উইলসনের ১৪ দফা বিরক্তিকর। আলজাজিরার সঙ্গে জালুদের সাক্ষাতকার এবং তার দৃষ্টিভঙ্গীর বিষয়ে অন্যান্য টুইটার ব্যবহারকারীরা মন্তব্য করেন ক্লাব তাই আসুন এখন আমরা একবার পরীক্ষা করে দেখি যে তাদের এই দাবি সত্যি কি না। ওমানের শাসক সুলতান কাবুস বিন সাইদের সমালোচনা করার অপরাধে আলরাওয়াহিকে শাস্তি প্রদানের পর গ্লোবাল ভয়েসেস এডভোকেসিতে ২০১২ সালে তাকে লক্ষ্যনীয়ভাবে উপস্থাপন করা হয়। আমাকে না বললেও আমি কাউকে বলতাম না। ভালুককে একটা আলিঙ্গন করে জড়িয়ে ধরে।  ১ পিতর ৫৫ আমরা আমাদের ভাইদের সঙ্গে যেভাবে ব্যবহার করি তা যিহোবার সঙ্গে আমাদের সম্পর্কের ওপর একটা বড় ছাপ ফেলে। ১ যোহন ৪২০ দায়িত্ব উনি ফল ছাড়া আর কিছুই খান না। আমার নাম এজাক্স এর সদস্যদের মধ্যে একজন ছিলেন লন্ডনস্থ ইন্ডিয়া হাউসের বীরেন চট্টোপাধ্যায় রবীন্দ্রনাথ ঠাকুর'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(file_p)"
      ],
      "metadata": {
        "id": "dqYv-ipOUnTK",
        "outputId": "94d0f3ff-f328-4cf6-8691-aebd63f1c735",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "176558564"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 7: Data Statistics"
      ],
      "metadata": {
        "id": "DESJn7S31MeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bnltk = NLTKTokenizer()\n",
        "\n",
        "sentences = bnltk.sentence_tokenize(file_p[:10000])\n",
        "print(\"The number of sentences is\", len(sentences)) \n",
        "\n",
        "words = bnltk.word_tokenize(file_p)\n",
        "print(\"The number of tokens is\", len(words)) \n",
        "\n",
        "average_tokens = round(len(words)/len(sentences))\n",
        "print(\"The average number of tokens per sentence is\", average_tokens) \n",
        "\n",
        "unique_tokens = set(words)\n",
        "print(\"The number of unique tokens are\", len(unique_tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jyOnleU09Q4",
        "outputId": "9adfe459-1b46-4962-967f-aa4a36511ad0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of sentences is 85\n",
            "The number of tokens is 29321128\n",
            "The average number of tokens per sentence is 344954\n",
            "The number of unique tokens are 747894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1: N-gram Models (bigram, trigram)\n"
      ],
      "metadata": {
        "id": "VyKiA0Yf1SWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bnlp.corpus import stopwords, punctuations, letters, digits\n",
        "\n",
        "bigram=[]\n",
        "trigram=[]\n",
        "\n",
        "# create bigram and trigram models \n",
        "for sentence in sentences:\n",
        "    sequence = bnltk.word_tokenize(sentence) \n",
        "    bigram.extend(list(ngrams(sequence, 2)))  \n",
        "    trigram.extend(list(ngrams(sequence, 3)))"
      ],
      "metadata": {
        "id": "zidRp1rM09T3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(bigram[:5])"
      ],
      "metadata": {
        "id": "CHFbtQfO09Ww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85604df4-cd24-49b1-9cb4-b4e026c782ff"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('আবার', 'সবাইকে'), ('সবাইকে', 'যার'), ('যার', 'যার'), ('যার', 'ইচ্ছামতো'), ('ইচ্ছামতো', 'চলতে')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(trigram[:5])"
      ],
      "metadata": {
        "id": "exr_c_tx09Zx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eeee475-12a0-4f37-a290-f3fa4e2de64f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('আবার', 'সবাইকে', 'যার'), ('সবাইকে', 'যার', 'যার'), ('যার', 'যার', 'ইচ্ছামতো'), ('যার', 'ইচ্ছামতো', 'চলতে'), ('ইচ্ছামতো', 'চলতে', 'দিলে')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3: Word frequencies using Zipf's law"
      ],
      "metadata": {
        "id": "An6WpMdV1cc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "from operator import itemgetter\n",
        "\n",
        "\n",
        "# Calculate the frequency of the words inside\n",
        "frequency = {}\n",
        "for word in words:\n",
        "    count = frequency.get(word , 0)\n",
        "    frequency[ word ] = count + 1\n",
        "\n",
        "rank = 1\n",
        "column_header = ['Rank', 'Frequency', 'Frequency * Rank']\n",
        "df = pd.DataFrame( columns = column_header )\n",
        "collection = sorted(frequency.items(), key=itemgetter(1), reverse = True)\n",
        "\n",
        "for word , freq in collection[:1000]:\n",
        "    df.loc[word] = [rank, freq, rank*freq]\n",
        "    rank = rank + 1\n",
        "    \n",
        "df.head()"
      ],
      "metadata": {
        "id": "LT80op3Q09gC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "54b2d152-c4c0-4fb8-b69b-3ded4fb53990"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Rank Frequency Frequency * Rank\n",
              "।      1   1548400          1548400\n",
              "এবং    2    362589           725178\n",
              "করে    3    265392           796176\n",
              "ও      4    253600          1014400\n",
              "করা    5    229747          1148735"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af0a39ea-d44e-4f87-a84f-e1171696d568\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rank</th>\n",
              "      <th>Frequency</th>\n",
              "      <th>Frequency * Rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>।</th>\n",
              "      <td>1</td>\n",
              "      <td>1548400</td>\n",
              "      <td>1548400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>এবং</th>\n",
              "      <td>2</td>\n",
              "      <td>362589</td>\n",
              "      <td>725178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>করে</th>\n",
              "      <td>3</td>\n",
              "      <td>265392</td>\n",
              "      <td>796176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ও</th>\n",
              "      <td>4</td>\n",
              "      <td>253600</td>\n",
              "      <td>1014400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>করা</th>\n",
              "      <td>5</td>\n",
              "      <td>229747</td>\n",
              "      <td>1148735</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af0a39ea-d44e-4f87-a84f-e1171696d568')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-af0a39ea-d44e-4f87-a84f-e1171696d568 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-af0a39ea-d44e-4f87-a84f-e1171696d568');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 4: Stemming and Lemmatisation"
      ],
      "metadata": {
        "id": "jIrbvq8s1if_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bnlp.corpus.util import remove_stopwords\n",
        "from bltk.langtools import remove_stopwords\n",
        "\n",
        "stop_words = remove_stopwords(sentences)"
      ],
      "metadata": {
        "id": "2kzbO35VpZBG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bangla_stemmer.stemmer import stemmer\n",
        "\n",
        "stemmer = stemmer.BanglaStemmer()\n",
        "\n",
        "# Stemming the words\n",
        "# steming_words = [stemmer.stem(word) for word in words if not word in stop_words]\n",
        "\n",
        "for word in words[:20]:\n",
        "  if not word in stop_words:\n",
        "    print(word+' -> '+ stemmer.stem(word))"
      ],
      "metadata": {
        "id": "egvtGhTb09mS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4870620-636d-4340-f165-514c3f10d593"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "applied fourth rules..\n",
            "আবার -> আব\n",
            "applied first rules..\n",
            "সবাইকে -> সবাইকে\n",
            "applied fourth rules..\n",
            "যার -> যার\n",
            "applied fourth rules..\n",
            "যার -> যার\n",
            "applied first rules..\n",
            "applied second rules..\n",
            "ইচ্ছামতো -> ইচ্ছামতো\n",
            "applied first rules..\n",
            "চলতে -> চল\n",
            "দিলে -> দিলে\n",
            "সমতা -> সমতা\n",
            "রক্ষা -> রক্ষা\n",
            "applied first rules..\n",
            "করা -> কর\n",
            "অসম্ভব -> অসম্ভব\n",
            "applied second rules..\n",
            "হয়ে -> হয়\n",
            "যায় -> যায়\n",
            "। -> ।\n",
            "তুরুপ -> তুরুপ\n",
            "applied fourth rules..\n",
            "পদদলিত -> পদদলিত\n",
            "applied first rules..\n",
            "করা -> কর\n",
            "applied third rules..\n",
            "সেগুলো -> সেই\n",
            "applied first rules..\n",
            "হৃদয়কে -> হৃদয়\n",
            "উষ্ণ -> উষ্ণ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from banglakit import lemmatizer as lem\n",
        "from banglakit.lemmatizer import BengaliLemmatizer\n",
        "\n",
        "\n",
        "lemmatizer = BengaliLemmatizer()\n",
        "\n",
        "# Lemmatizing the words\n",
        "# lematizing_words = [lemmatizer.lemmatize(word) for word in words if not word in stop_words]\n",
        "\n",
        "for word in words[:20]:\n",
        "  if not word in stop_words:\n",
        "    print(word+' -> '+ lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "id": "C3-uX00J09pV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f73a9f4f-7c7c-4350-e8a3-6feb671880ba"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "আবার -> আবার\n",
            "সবাইকে -> সবাইকে\n",
            "যার -> যার\n",
            "যার -> যার\n",
            "ইচ্ছামতো -> ইচ্ছামতো\n",
            "চলতে -> চলতে\n",
            "দিলে -> দিলে\n",
            "সমতা -> সমতা\n",
            "রক্ষা -> রক্ষা\n",
            "করা -> কর\n",
            "অসম্ভব -> অসম্ভব\n",
            "হয়ে -> হয়ে\n",
            "যায় -> যাওয়া\n",
            "। -> ।\n",
            "তুরুপ -> তুরুপ\n",
            "পদদলিত -> পদদলিত\n",
            "করা -> কর\n",
            "সেগুলো -> সেগুলো\n",
            "হৃদয়কে -> হৃদয়কে\n",
            "উষ্ণ -> উষ্ণ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 5: Sentence repetition"
      ],
      "metadata": {
        "id": "VihGuH8k1tcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duplicates = []\n",
        "cleaned = []\n",
        "for sentence in sentences[:20000]:\n",
        "    if sentence in cleaned:\n",
        "        if sentence in duplicates:\n",
        "            continue\n",
        "        else:\n",
        "            duplicates.append(sentence)\n",
        "    else:\n",
        "        cleaned.append(sentence)\n",
        "\n",
        "print(duplicates)"
      ],
      "metadata": {
        "id": "o1kHUJD909sT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "074ad003-3084-4549-cdd4-078096edb118"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 6: Tf-Idf measurements"
      ],
      "metadata": {
        "id": "Fz3cBuzb1xsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vec = TfidfVectorizer(use_idf=True,tokenizer=lambda x: x.split())\n",
        "\n",
        "tf_idf =  vec.fit_transform(sentences[:5])\n",
        "print(pd.DataFrame(tf_idf.toarray(), columns=vec.get_feature_names()))"
      ],
      "metadata": {
        "id": "b1qR8w3M09vX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68be111e-9045-4cc0-9a61-d8fa093e4bcd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     ।    অভিযোগ    অসম্ভব      আবার  আমি  ইচ্ছামতো   উইলসনের      উষ্ণ  \\\n",
            "0  0.0  0.000000  0.261257  0.261257  0.0  0.261257  0.000000  0.000000   \n",
            "1  0.0  0.000000  0.000000  0.000000  0.0  0.000000  0.000000  0.302161   \n",
            "2  0.5  0.000000  0.000000  0.000000  0.5  0.000000  0.000000  0.000000   \n",
            "3  0.0  0.000000  0.000000  0.000000  0.0  0.000000  0.215989  0.000000   \n",
            "4  0.0  0.354602  0.000000  0.000000  0.0  0.000000  0.286091  0.000000   \n",
            "\n",
            "     এছাড়াও       এবং  ...   লিমিটেড     সংশয়ী    সবাইকে      সমতা    সেগুলো  \\\n",
            "0  0.000000  0.000000  ...  0.000000  0.000000  0.261257  0.261257  0.000000   \n",
            "1  0.000000  0.243782  ...  0.000000  0.000000  0.000000  0.000000  0.302161   \n",
            "2  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "3  0.267713  0.215989  ...  0.267713  0.267713  0.000000  0.000000  0.000000   \n",
            "4  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "\n",
            "       হতাশ     হালকা    হৃদয়কে       হয়ে        ১৪  \n",
            "0  0.000000  0.000000  0.000000  0.261257  0.000000  \n",
            "1  0.000000  0.302161  0.302161  0.000000  0.000000  \n",
            "2  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "3  0.267713  0.000000  0.000000  0.000000  0.215989  \n",
            "4  0.000000  0.000000  0.000000  0.000000  0.286091  \n",
            "\n",
            "[5 rows x 47 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9UHKtSIk09yU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4KfvciaL091V"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}